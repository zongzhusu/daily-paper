"""daily-paper pipeline runner (collect -> score -> curate -> build-site).

This runner is designed for cron execution.

Outputs (by date):
- output/YYYY-MM-DD.json  (payload with {date, items})
- output/site/*.html      (static site generated by web/generate.js)

Env knobs (optional):
- DAILY_PAPER_MAX_ITEMS (default 30)
- DAILY_PAPER_TOPK (default 10)
"""

from __future__ import annotations

import json
import os
import subprocess
import sys
from dataclasses import dataclass
from datetime import date
from pathlib import Path
from typing import Any

import yaml

from .curate import normalize_entry
from .score import score_items
from .topic_mapper import map_topic


@dataclass
class Paths:
    root: Path
    output_dir: Path
    output_site: Path
    tmp_dir: Path

    @staticmethod
    def from_root(root: Path) -> "Paths":
        return Paths(
            root=root,
            output_dir=root / "output",
            output_site=root / "output" / "site",
            tmp_dir=root / ".tmp",
        )


def default_run_date() -> str:
    return date.today().isoformat()


def write_json(path: Path, payload: object) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


def load_yaml(path: Path) -> dict[str, Any]:
    if not path.exists():
        return {}
    return yaml.safe_load(path.read_text(encoding="utf-8")) or {}


def run_node_json(cmd: list[str], *, cwd: Path, out_path: Path) -> dict[str, Any]:
    proc = subprocess.run(cmd, cwd=str(cwd), text=True, capture_output=True)
    if proc.returncode != 0 and proc.stdout.strip() == "":
        raise RuntimeError(f"command failed: {' '.join(cmd)}\nexit={proc.returncode}\nstderr:\n{proc.stderr}")
    out_path.write_text(proc.stdout, encoding="utf-8")
    return json.loads(proc.stdout)


def run_daily(run_date: str, *, mode: str = "paper") -> Path:
    root = Path(__file__).resolve().parents[1]
    paths = Paths.from_root(root)

    paths.output_dir.mkdir(parents=True, exist_ok=True)
    paths.output_site.mkdir(parents=True, exist_ok=True)
    paths.tmp_dir.mkdir(parents=True, exist_ok=True)

    _ = load_yaml(root / "config" / "pipeline.yaml")
    __ = load_yaml(root / "config" / "topics.yaml")
    ___ = mode

    # 1) collect (paper_v0)
    collect_req = {
        "mode": "paper_v0",
        "config": {},
        "run": {
            "maxItems": int(os.getenv("DAILY_PAPER_MAX_ITEMS", "30")),
            # Ensure papers match the requested run_date in local timezone.
            "date": run_date,
            "timeZone": os.getenv("DAILY_PAPER_TIMEZONE", "Asia/Shanghai"),
        },
    }
    collect_req_path = paths.tmp_dir / f"collect-{run_date}.json"
    collect_out_path = paths.tmp_dir / f"collect-result-{run_date}.json"
    write_json(collect_req_path, collect_req)

    collect_result = run_node_json(
        ["node", "/root/.openclaw/skills/news-collector/scripts/arxiv_collect.js", "--input", str(collect_req_path)],
        cwd=root,
        out_path=collect_out_path,
    )

    collected_items = collect_result.get("items") or []
    if not isinstance(collected_items, list):
        raise RuntimeError("collector output missing items list")

    # 2) score (LLM top-k)
    scored = score_items(collected_items)

    # 3) map topic + normalize
    normalized_items: list[dict[str, Any]] = []
    for item in scored:
        try:
            item = dict(item)
            item["topic"] = item.get("topic") or map_topic(item)
            # add urls if missing
            arxiv_id = (item.get("arxiv_id") or "").strip()
            if arxiv_id:
                item.setdefault("abs_url", f"https://arxiv.org/abs/{arxiv_id}")
                item.setdefault("pdf_url", f"https://arxiv.org/pdf/{arxiv_id}.pdf")
            normalized = normalize_entry(item)
            if normalized:
                normalized_items.append(normalized)
        except Exception:
            continue

    payload = {"date": run_date, "items": normalized_items}

    out_json = paths.output_dir / f"{run_date}.json"
    write_json(out_json, payload)

    # 4) build site
    subprocess.run(["node", "web/generate.js", "--mode", mode], cwd=str(root), check=True)

    return out_json


def main(argv: list[str]) -> int:
    run_date = default_run_date()
    mode = "paper"

    i = 0
    while i < len(argv):
        token = argv[i]
        if token == "--date":
            run_date = argv[i + 1]
            i += 2
            continue
        if token == "--mode":
            mode = argv[i + 1]
            i += 2
            continue
        i += 1

    out_json = run_daily(run_date, mode=mode)
    print(f"[daily-paper] OK: {out_json}")
    return 0


if __name__ == "__main__":
    try:
        raise SystemExit(main(sys.argv[1:]))
    except Exception as e:
        print(f"[daily-paper] ERROR: {e}", file=sys.stderr)
        raise SystemExit(2)
